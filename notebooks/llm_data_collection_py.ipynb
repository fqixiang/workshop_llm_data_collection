{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHhOlhjzjH0H"
      },
      "source": [
        "# Using Large Language Models for Data Collection in Social Sciences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2e1RcGZrj4e5"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install -qU langchain[openai] tqdm pydantic krippendorff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1B9Ok90OkqZC"
      },
      "outputs": [],
      "source": [
        "import getpass  # Provides a secure way to handle user passwords or other sensitive input without echoing them on the screen.\n",
        "import os  # Gives access to operating system functionalities like file paths, environment variables, and directory operations.\n",
        "import pandas as pd  # Imports the pandas library (aliased as pd) for handling and analyzing tabular data in DataFrames.\n",
        "import numpy as np  # Imports NumPy (aliased as np), a library for fast numerical computations and array manipulations.\n",
        "from tqdm import tqdm  # Imports tqdm, a progress bar utility that provides visual feedback for loops and long-running processes.\n",
        "from langchain.chat_models import init_chat_model  # Imports a function from LangChain to initialize a chat-based large language model (LLM) interface.\n",
        "from langchain_core.prompts import ChatPromptTemplate  # Imports a template class for creating structured prompts used in LLM interactions.\n",
        "from pydantic import BaseModel, Field  # Imports BaseModel (for defining structured data models) and Field (for specifying metadata and validation rules).\n",
        "import krippendorff  # Imports the krippendorff library, used to compute Krippendorff’s alpha — a reliability measure for agreement among raters or annotators."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE3OlfYOlb0G"
      },
      "source": [
        "## Gabrielle Martins van Jaarsveld's SoDa fellowship dataset\n",
        "\n",
        "Feel free to use your own data. By default, we will use a toy dataset from Gabrielle Martins van Jaarsveld's SoDa fellowship project on annotating markers of self-regulated learning from student conversation data.\n",
        "\n",
        "This dataset contains the following columns:\n",
        "\n",
        "- `id`: The id of the row/conversation/student.\n",
        "\n",
        "- `conversation`: The text of the conversations based on which specificity scores are derived (by humans or LLMs).\n",
        "\n",
        "- `score_specificity_llm`: The specificity score of a conversation based on carefully prompted response from LLMs. It varies between 0, 1 and 2.\n",
        "\n",
        "- `score_specificity_human`: The specificity score of a conversation based on human expert annotators. It is treated as gold standard (i.e., free from measurement error). It varies between 0, 1 and 2.\n",
        "\n",
        "- `performance`: The academic performance of a student, varying from 1 to 10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-LyJLcM4RzT"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "w6iO_UFkm2aQ"
      },
      "outputs": [],
      "source": [
        "# Download our example data from a url\n",
        "data_url = \"https://sodascience.github.io/workshop_llm_data_collection/data/srl_data_example.csv\"\n",
        "\n",
        "# Read CSV into dataframe\n",
        "df = pd.read_csv(data_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0lSfXdFEb7z"
      },
      "source": [
        "Display the first 10 rows of the dataset.\n",
        "\n",
        "Note that only the first 10 rows contain the text of the conversations. We will use these texts for the prompting experiments to come."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kvZ5ZgGIEepO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "6c8d92cc-053d-4a82-c9ec-77fbaae37b70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id                                       conversation  \\\n",
              "0   request_1  PROMPT: Set an academic goal for the upcoming ...   \n",
              "1   request_2  PROMPT: Set an academic goal for the upcoming ...   \n",
              "2   request_3  PROMPT: Set an academic goal for the upcoming ...   \n",
              "3   request_4  PROMPT: Set an academic goal for the upcoming ...   \n",
              "4   request_5  PROMPT: Set an academic goal for the upcoming ...   \n",
              "5   request_6  PROMPT: Set an academic goal for the upcoming ...   \n",
              "6   request_7  PROMPT: Set an academic goal for the upcoming ...   \n",
              "7   request_8  PROMPT: Set an academic goal for the upcoming ...   \n",
              "8   request_9  PROMPT: Set an academic goal for the upcoming ...   \n",
              "9  request_10  PROMPT: Set an academic goal for the upcoming ...   \n",
              "\n",
              "   score_specificity_llm  score_specificity_human  performance  \n",
              "0                      1                      1.0          3.5  \n",
              "1                      2                      2.0          6.8  \n",
              "2                      0                      0.0          6.7  \n",
              "3                      1                      1.0          7.3  \n",
              "4                      1                      1.0          5.8  \n",
              "5                      1                      1.0          6.4  \n",
              "6                      2                      1.0          5.9  \n",
              "7                      0                      0.0          7.6  \n",
              "8                      1                      1.0          7.6  \n",
              "9                      2                      2.0          7.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aecb6776-c07f-4c61-ab0a-7012fcf905cf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>conversation</th>\n",
              "      <th>score_specificity_llm</th>\n",
              "      <th>score_specificity_human</th>\n",
              "      <th>performance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>request_1</td>\n",
              "      <td>PROMPT: Set an academic goal for the upcoming ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>request_2</td>\n",
              "      <td>PROMPT: Set an academic goal for the upcoming ...</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>request_3</td>\n",
              "      <td>PROMPT: Set an academic goal for the upcoming ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>request_4</td>\n",
              "      <td>PROMPT: Set an academic goal for the upcoming ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>request_5</td>\n",
              "      <td>PROMPT: Set an academic goal for the upcoming ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>request_6</td>\n",
              "      <td>PROMPT: Set an academic goal for the upcoming ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>request_7</td>\n",
              "      <td>PROMPT: Set an academic goal for the upcoming ...</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>request_8</td>\n",
              "      <td>PROMPT: Set an academic goal for the upcoming ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>request_9</td>\n",
              "      <td>PROMPT: Set an academic goal for the upcoming ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>request_10</td>\n",
              "      <td>PROMPT: Set an academic goal for the upcoming ...</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aecb6776-c07f-4c61-ab0a-7012fcf905cf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aecb6776-c07f-4c61-ab0a-7012fcf905cf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aecb6776-c07f-4c61-ab0a-7012fcf905cf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3c333695-ac07-4443-8b9b-9c28028c0980\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3c333695-ac07-4443-8b9b-9c28028c0980')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3c333695-ac07-4443-8b9b-9c28028c0980 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 80,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 80,\n        \"samples\": [\n          \"request_31\",\n          \"request_1\",\n          \"request_23\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"conversation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"PROMPT: Set an academic goal for the upcoming week.\\nANSWER: I would like to keep on track with the readings I have to do\\nPROMPT: Add details to make your goal more specific.\\nANSWER: Every week we have two tutorials, which are smaller groups, where we have a debate about the readings we have done before. Each week for both of them we have more than 100 pages to read and we need to arrive prepared at the tutorial. So I would like to manage better my time in order to arrive prepared at every tutorial with all the readings well done\\nPROMPT: How will you measure progress on and acheivement of your goal?\\nANSWER: I can decide how many pages I have to study each day\\nPROMPT: Why is this goal important to you in the context of your prior experiences and future goals?\\nANSWER: I think is good because it will help me in manage my time better, but also i will have more time for myself, for working, hanging out with friends. I also think is fundamental to learn how to manage many things all together at the same time now at university, because later on it will be even worse\\nPROMPT: Create a step-by-step plan for achieving this goal in the coming week.\\nANSWER: At first I will count all the pages i have to do, so that i know exactly how much work is, after I will take the calendar and i will divide the work for every day, writing precisely how many pages i should do each day. After that, every day i will try to stick to the plan as much as possible and maybe to motivate myself, I will decide a reward that I can have just if i manage to do everything that was written in the plan of the day\",\n          \"PROMPT: Set an academic goal for the upcoming week.\\nANSWER: I would like write notes on theme 1 from my mathematics course. \\nPROMPT: Add details to make your goal more specific.\\nANSWER: I will take notes on Chapter 1 from the Basic Algebra book and the two articles that belonged to theme 1\\nPROMPT: How will you measure progress on and acheivement of your goal?\\nANSWER: I will split it into three parts. First the book chapter, then the first article and lastly the second article. When there is well written notes that sums up the important parts from the reading i will have achieved my goal.\\nPROMPT: Why is this goal important to you in the context of your prior experiences and future goals?\\nANSWER: By achieving this goal I will remember and understand the material better, which will make it easier so study for the upcoming exam. I will not feel as overwhelmed as for earlier exam because I have made good notes that I can go through instead of going through all the materials.\\nPROMPT: Create a step-by-step plan for achieving this goal in the coming week.\\nANSWER: 1. Go to a nice cafe where I can study uninterrupted \\n2. Read through the highlighted parts of the book chapter and simultaneously write down notes for it. \\n3. Read through the highlighted parts of the first article and simultaneously write down notes for it. \\n4. Read through the highlighted parts of the second article and simultaneously write down notes for it. \\n5. Red over all the notes and check that it makes sense and give a good summary of the important parts of the material.\",\n          \"PROMPT: Set an academic goal for the upcoming week.\\nANSWER: Doing the reading and taking notes before class\\nPROMPT: Add details to make your goal more specific.\\nANSWER: I would like to read the given pages before my classes, which are on Mondays, Wednesdays, and Thursdays. Each class requires us to have read certain pages and articles, and then discuss in class. However, I have troubles which time management, which is why I never get the reading done in time and then cram before exams\\nPROMPT: How will you measure progress on and acheivement of your goal?\\nANSWER: I will measure my progress by examinig the notes I have prepared for every class, and we can measure if Ive achieved it by maybe asking some questions about the literature?\\nPROMPT: Why is this goal important to you in the context of your prior experiences and future goals?\\nANSWER: Because cramming all the material before exams has had a severe impact on my grades, and Im trying to fix my average with the upcoming exams, so I need to ensure that my method will give me best results\\nPROMPT: Create a step-by-step plan for achieving this goal in the coming week.\\nANSWER: Start every preperation with a video explaining the concept briefly, then read the literature while taking notes by hand. Have all this done latest a day before the lesson.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_specificity_llm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_specificity_human\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6914918072835209,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.0,\n          2.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"performance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.282136449007622,\n        \"min\": 1.2,\n        \"max\": 8.7,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          7.2,\n          8.7,\n          8.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhiH0VRqljn2"
      },
      "source": [
        "## Using langchain to call OpenAI's API\n",
        "\n",
        "We will be using the Python package `langchain` to perform our prompting experiments. One great advantage of using `langchain` is that it takes away the trouble of having to learn different LLM APIs. Instead, it allows you to call different LLM APIs (both commercial and open-source) effortlessly (relatively speaking) with very simple modifications of your `langchain` code!\n",
        "\n",
        "We will be calling OpenAI's LLM in this notebook. Feel free to experiment with other APIs and models! To do so, check out https://python.langchain.com/docs/tutorials/chatbot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUBe3-xbMq-e"
      },
      "source": [
        "Initialise an LLM model. You need to enter your OpenAI API key for this when being prompted. Don't have one? Ask the workshop instructors!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "D01Wli7ilI83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53a1b4b2-9b8e-44f0-ccba-3b052ba9c9fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter API key for OpenAI: ··········\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
        "model = init_chat_model(\"gpt-4o-mini\",\n",
        "                        model_provider=\"openai\",\n",
        "                        temperature=0,\n",
        "                        max_tokens=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5bCH0msmBNC"
      },
      "source": [
        "## Working with a single prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7pQ9bJjeYpL"
      },
      "source": [
        "Let's start with the system prompt (i.e., high-level instruction to the model)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6DHz1SuRp964"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"\"\"\n",
        "You are an expert in educational assessment and goal evaluation, with\n",
        "specialized expertise in applying deductive coding schemes to score the quality\n",
        "and content of student goals.\n",
        "\n",
        "##TASK##\n",
        "A university student was given a series of prompts, guiding them through the\n",
        "process of setting and elaborating on an academic goal for the coming week. You\n",
        "will be provided with the entire conversation including the prompts, and the\n",
        "student answers. Your objective is to assess the specificity of of the student’s\n",
        "goal on a scale of 0 to 2 based on the entire conversation.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HivI2QseewJ"
      },
      "source": [
        "Use the prompt template module from langchain to create a prompt request with both **system** and **user** prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bEQtu3AcWlVn"
      },
      "outputs": [],
      "source": [
        "prompt_template = ChatPromptTemplate([\n",
        "    (\"system\", system_prompt),\n",
        "    (\"user\", \"{conversation}\")\n",
        "])\n",
        "\n",
        "# Create a prompt request with the system prompt and the user prompt based on\n",
        "# the first conversation from the dataset\n",
        "prompt_request = prompt_template.invoke({\"conversation\": df.iloc[0,1]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_CixxrPel8s"
      },
      "source": [
        "Check the prompt before prompting the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jam82IDfLz2Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cca40c29-05a3-4ad4-fe90-ec2426e93b61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='\\nYou are an expert in educational assessment and goal evaluation, with\\nspecialized expertise in applying deductive coding schemes to score the quality\\nand content of student goals.\\n\\n##TASK##\\nA university student was given a series of prompts, guiding them through the\\nprocess of setting and elaborating on an academic goal for the coming week. You\\nwill be provided with the entire conversation including the prompts, and the\\nstudent answers. Your objective is to assess the specificity of of the student’s\\ngoal on a scale of 0 to 2 based on the entire conversation.\\n', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='PROMPT: Set an academic goal for the upcoming week.\\nANSWER: I would like to catch up on my geography reading\\nPROMPT: Add details to make your goal more specific.\\nANSWER: I need to either read the book from last week and this week, or read my friends notes on the reading to take notes of my own so I dont fall behind.\\nPROMPT: How will you measure progress on and acheivement of your goal?\\nANSWER: by the number of pages I write per day\\nPROMPT: Why is this goal important to you in the context of your prior experiences and future goals?\\nANSWER: It is important to achieve because if I dont, I will fall behind and most likely wont be ready for the exam.\\nPROMPT: Create a step-by-step plan for achieving this goal in the coming week.\\nANSWER: 1. evaluate how much there is to do \\n2. get help from my friends \\n3. takes notes day by day', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "prompt_request.to_messages()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWHolr5NetK-"
      },
      "source": [
        "Prompt the model and inspect the response!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Chb3505UWnfk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc806c6-8fff-4845-e4e1-6c8db50aa7f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To assess the specificity of the student's goal, we can evaluate each part of their responses based on clarity, detail, and measurability.\n",
            "\n",
            "1. **Initial Goal**: \"I would like to catch up on my geography reading.\" \n",
            "   - This is a broad statement and lacks specificity. It does not indicate how much reading is required or what specific materials will be used. **Score: 0**\n",
            "\n",
            "2. **Details Added**: \"I need to either read the book from last week and this week, or read my friends notes on the reading to take notes of my own so I don't fall behind.\"\n",
            "   - This response provides more detail by specifying the materials (the book and friends' notes) and the purpose (to take notes and not fall behind). However, it still lacks a clear plan on how much reading will be done or a timeline. **Score: 1**\n",
            "\n",
            "3. **Measuring Progress**: \"by the number of pages I write per day.\"\n",
            "   - This is a measurable aspect of the goal, as it provides a clear metric (number of pages) to track progress. However, it does not specify a target number of pages or a timeframe for completion. **Score: 1**\n",
            "\n",
            "4. **Importance of the Goal**: \"It is important to achieve because if I don't, I will fall behind and most likely won't be ready for the exam.\"\n",
            "   - This response explains the importance of the goal in relation to the student's academic performance and future exams, which adds context but does not enhance specificity. **Score: 1**\n",
            "\n",
            "5. **Step-by-Step Plan**: \n",
            "   - \"1. evaluate how much there is to do \n",
            "     2. get help from my friends \n",
            "     3. takes notes day by day\"\n",
            "   - The steps provide a basic framework for achieving the goal, but they are still quite general. For example, \"evaluate how much there is to do\" lacks specifics on how this evaluation will be conducted or what criteria will be used. **Score: 1**\n",
            "\n",
            "Overall, while the student has made some progress in specifying their goal, it still lacks clarity and detailed planning. The goal is somewhat measurable but does not have a clear target or timeline. \n",
            "\n",
            "**Final Assessment Score: 1** (on a scale of 0 to 2) for specificity.\n"
          ]
        }
      ],
      "source": [
        "response = model.invoke(prompt_request)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MfKrGf3e4MZ"
      },
      "source": [
        "Voila! You have your first successful prompting interaction with the API of a large language model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teHsF27YceX_"
      },
      "source": [
        "## Working with multiple prompts\n",
        "Next, we are going beyond a single prompt. Instead, we will work with **multiple prompts** at the same time!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hhigdP9THoO"
      },
      "source": [
        "Define a list of request IDs and another list of conversations (necessary for forming the user prompts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UAfnxKlQf4eQ"
      },
      "outputs": [],
      "source": [
        "ids = df.id[:10].tolist()\n",
        "conversations = df.conversation[:10].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Y0b78F6Chy_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a722b6-0509-4f39-d7ea-93aa44346ce6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Requests: 100%|██████████| 10/10 [01:46<00:00, 10.68s/it]\n"
          ]
        }
      ],
      "source": [
        "responses = {}\n",
        "for id, conversation in tqdm(zip(ids, conversations),\n",
        "                             total=len(ids),\n",
        "                             desc=\"Processing Requests\"):\n",
        "    prompt_request = prompt_template.invoke({\"conversation\": conversation})\n",
        "    response = model.invoke(prompt_request)\n",
        "    responses[id] = response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9lYcc12LFht"
      },
      "source": [
        "Inspect the responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "f3KOt37Hi-UX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70682d2f-a019-45d9-bdff-5066e434b924"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To assess the specificity of the student's goal, we can evaluate each part of the conversation.\n",
            "\n",
            "1. **Initial Goal**: \"To not procrastinate\" - This goal is quite vague and lacks specificity. It does not define what tasks the student is referring to or how they plan to avoid procrastination. **Score: 0**\n",
            "\n",
            "2. **Details Added**: \"To not spend a lot of time on my phone, and leave a lot of the reading till the last minute, and not late into the night\" - This response provides more context about the behaviors the student wants to change, but it still lacks clear, actionable steps or specific tasks. It mentions reducing phone time and avoiding last-minute reading, but does not specify what readings or assignments are involved. **Score: 1**\n",
            "\n",
            "3. **Measurement of Progress**: \"By finishing work at a certain time of the day\" - This indicates a measurable aspect of the goal, but it does not specify what that time is or what \"work\" entails. It suggests a method of tracking progress but lacks clarity on the specifics. **Score: 1**\n",
            "\n",
            "4. **Importance of the Goal**: \"To help me strategically work, and study smart\" - This provides some insight into the motivation behind the goal but does not add specificity to the goal itself. **Score: 0**\n",
            "\n",
            "5. **Step-by-Step Plan**: \n",
            "   - \"1. I will reduce my phone time\" - This is a specific action but lacks a defined limit or timeframe.\n",
            "   - \"2. I will organize my workload\" - This is somewhat vague; it does not specify how the workload will be organized.\n",
            "   - \"3. I will spread my workload evenly across the week\" - This is a clearer action, but it still lacks specifics about what tasks will be spread out. **Score: 1**\n",
            "\n",
            "Overall, while the student made some progress in specifying their goal, it remains somewhat vague and lacks clear, actionable steps. The final assessment of specificity based on the entire conversation would be a **total score of 1**.\n"
          ]
        }
      ],
      "source": [
        "print(responses['request_3'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59gpSzXadJej"
      },
      "source": [
        "## Using structured output with a single prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuEez0lGTf78"
      },
      "source": [
        "To force the LLM to produce outputs in formats specified by you, you need to use the `BaseModel` and `Field` classes from the `pydantic` package.\n",
        "\n",
        "Below, we define our desired output format as:\n",
        "- \"specificity_score\": an integer (either 0, 1 or 2) reflecting the specificity of a conversation.\n",
        "- \"reasoning\": a string that provides the model's reasoning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hbluX4wfdPqx"
      },
      "outputs": [],
      "source": [
        "class SpecificityFormat(BaseModel):\n",
        "    \"\"\"Always use this tool to structure your response to the user.\"\"\"\n",
        "    specificity_score: int = Field(description=\"The specificity score of the entire conversation on a scale of 0, 1 and 2.\")\n",
        "    reasoning: str = Field(description=\"Your reasoning process.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHATrS3zUpML"
      },
      "source": [
        "Try with a single prompt request."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8qFPaYJCmRUs"
      },
      "outputs": [],
      "source": [
        "# Bind responseformatter schema to the model\n",
        "model_structured = model.with_structured_output(SpecificityFormat)\n",
        "\n",
        "# Try to run a request throught this new model\n",
        "prompt_request = prompt_template.invoke({\"conversation\": df.iloc[0,1]})\n",
        "structured_response = model_structured.invoke(prompt_request)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "v1wxfPM6k7PJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "043d4f4b-3b12-41be-d813-24490d53458c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'specificity_score': 1,\n",
              " 'reasoning': \"The student's goal of catching up on geography reading is somewhat specific, as they mention reading the book from the previous week and this week or using a friend's notes. However, the details provided are still vague regarding the exact amount of reading or specific deadlines. The measurement of progress by the number of pages written per day adds some clarity, but it lacks a clear target or timeline. The importance of the goal is articulated, but the step-by-step plan is also quite general. Overall, while there is some specificity, it does not fully meet the criteria for a score of 2.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "dict(structured_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWmyBbl0LnOR"
      },
      "source": [
        "## Using structured output with multiple prompts\n",
        "\n",
        "Being able to work with multiple prompts at the same time and obtain structured output will save you a substantial amount of time in research projects!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "X6zuVgkJrqVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e46e7486-59fe-4d5b-87ac-46ff5b3f9749"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Messages: 100%|██████████| 10/10 [00:28<00:00,  2.84s/it]\n"
          ]
        }
      ],
      "source": [
        "structured_responses = {}\n",
        "for id, conversation in tqdm(zip(ids, conversations), total=len(ids), desc=\"Processing Messages\"):\n",
        "    prompt_request = prompt_template.invoke({\"conversation\": conversation})\n",
        "    structured_response = model_structured.invoke(prompt_request)\n",
        "    # Below we save only the specificity scores\n",
        "    structured_responses[id] = dict(structured_response)[\"specificity_score\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMyf6gljIsYV"
      },
      "source": [
        "Display all the structured responses (only the specificity scores)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5_NYNFRGsO2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15067daa-c545-4a03-85d6-de6fe82dbd9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'request_1': 1,\n",
              " 'request_2': 2,\n",
              " 'request_3': 1,\n",
              " 'request_4': 2,\n",
              " 'request_5': 2,\n",
              " 'request_6': 2,\n",
              " 'request_7': 2,\n",
              " 'request_8': 1,\n",
              " 'request_9': 2,\n",
              " 'request_10': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "structured_responses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3eLGxm5dW1f"
      },
      "source": [
        "## Check annotation quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hE7knNFJD54"
      },
      "source": [
        "Implement a handy function to calculate Krippendorff's Alpha (i.e., agreement) between two lists of specificity scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "q9zndWAmJBcQ"
      },
      "outputs": [],
      "source": [
        "def compute_krippendorff_alpha(x: list[int], y: list[int]):\n",
        "  # Format data into a reliability matrix (rows=raters, cols=items)\n",
        "  data_krippendorff = np.array([x, y])\n",
        "  # Compute Krippendorff’s Alpha (interval metric)\n",
        "  kripp_alpha = krippendorff.alpha(reliability_data=data_krippendorff, level_of_measurement='interval')\n",
        "  return kripp_alpha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRNqIXIqJN6-"
      },
      "source": [
        "Let's check the agreement between the specificity scores we got from the LLM above and the human expert-coded specificity scores!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "apooHATcs1wp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe2d426a-0a15-4afd-8dd9-382183560450"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Krippendorff's Alpha: 0.2222222222222222\n"
          ]
        }
      ],
      "source": [
        "score_specificity_human = df.score_specificity_human[:10].tolist()\n",
        "structured_response_values = list(structured_responses.values())\n",
        "print(\"Krippendorff's Alpha:\", compute_krippendorff_alpha(structured_response_values, score_specificity_human))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4kQllO3JhML"
      },
      "source": [
        "Not a great agreement score!\n",
        "\n",
        "How about the agreement between the LLM specificity scores that already came with the dataset (i.e., column `score_specificity_llm`) and the human expert-coded scores?\n",
        "\n",
        "Note that `score_specificity_llm` is based on prompts that were carefully engineered by Gabrielle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Z97P-AtdnR4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f93a2cb-63db-43ea-d5cb-648a332aad72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Krippendorff's Alpha: 0.8938547486033519\n"
          ]
        }
      ],
      "source": [
        "score_specificity_llm = df.score_specificity_llm[:10].tolist()\n",
        "print(\"Krippendorff's Alpha:\", compute_krippendorff_alpha(score_specificity_llm, score_specificity_human))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMRpL4zIKZOr"
      },
      "source": [
        "Wow! Much better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8I28nCUtjkFt"
      },
      "source": [
        "## Exercise: Try different prompting techniques to get better results!\n",
        "\n",
        "For example:\n",
        "\n",
        "1. Improve clarity & specificity\n",
        "2. Role-based prompting\n",
        "3. Step-by-step reasoning (Chain-of-Thought Prompting)\n",
        "4. Few-shot prompting\n",
        "5. Output structuring\n",
        "6. Self-consistency prompting\n",
        "\n",
        "Use the previous `compute_krippendorff_alpha` function to check the LLM's annotation quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTrRxc-LuktS"
      },
      "outputs": [],
      "source": [
        "# Let's write some code!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}